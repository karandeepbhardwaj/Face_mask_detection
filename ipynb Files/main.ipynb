{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([[1,1,0,1,0],[1,1,1,0,1],[0,0,1,0,0],[0,1,0,1,0],[1,0,1,1,1],[0,1,1,1,0],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0]\n",
      " [1 1 1 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 1 0]\n",
      " [1 0 1 1 1]\n",
      " [0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 1]\n",
      " [1 0 1 1]\n",
      " [0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "# features matrix\n",
    "X = iris.data\n",
    "# label vector\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(4,), max_iter=10000)\n",
    "mlp.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "print('Accuracy: %.2f'% accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, hl)\n",
    "        self.fc2 = nn.Linear(hl, 3)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = 4\n",
    "lr = 0.005\n",
    "num_epoch = 10000\n",
    "iris = load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1)\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0827, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7933, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5971, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5883, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5800, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5780, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5752, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    x = torch.Tensor(x_train).float()\n",
    "    y = torch.Tensor(y_train).long()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 is 0:\n",
    "        print(loss) # cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(x_test).float()\n",
    "y = torch.Tensor(y_test).long()\n",
    "y_pred = net(x)\n",
    "_, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "acc = torch.sum(y == predicted).numpy() / len(x_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
