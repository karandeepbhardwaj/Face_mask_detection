# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fUySG5BOayR-kjkOC5nbpLyPSsn4k4a8
"""

# Import required libraries
import torch 
import os
from tqdm import tqdm
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import cv2
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data.dataset import Dataset
from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor
from torch.utils.data.dataloader import DataLoader
from torchvision.utils import make_grid

"""**D**ownloading data from Kaggle.com"""

# Commented out IPython magic to ensure Python compatibility.
# # Getting data from kaggle.com
# %%capture
# # Keys for env - API
# os.environ['KAGGLE_USERNAME'] = "karandeepbhardwaj" # username from the json file
# os.environ['KAGGLE_KEY'] = "a188728f8e2873a3cd0394bd2b543ffb" # key from the json file
# 
# # Bash commands to download data and unzip in source directory
# !kaggle datasets download -d andrewmvd/animal-faces
# !kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset
# !unzip face-mask-12k-images-dataset.zip -d my_human_data
# !unzip animal-faces.zip -d my_not_human_data
# !rm -r sample_data
# !rm animal-faces.zip
# !rm face-mask-12k-images-dataset.zip
# !mkdir "./my_human_data/Face Mask Dataset/Train/Mask/"
# !mv "./my_human_data/Face Mask Dataset/Train/WithMask/" "./my_human_data/Face Mask Dataset/Train/Mask/"
# !mkdir "./my_human_data/Face Mask Dataset/Train/NoMask/"
# !mv "./my_human_data/Face Mask Dataset/Train/WithoutMask/" "./my_human_data/Face Mask Dataset/Train/NoMask/"
# !mkdir "./my_not_human_data/afhq/train/NotHuman/"
# !mv "./my_not_human_data/afhq/train/cat/" "./my_not_human_data/afhq/train/NotHuman/"



"""Paths to data folders created in source directory."""

#Data Loading
classes = ['Masked', 'NotMasked', 'NotHuman']

maskPath = './my_human_data/Face Mask Dataset/Train/Mask/'
nonMaskPath = './my_human_data/Face Mask Dataset/Train/NoMask/'
nonHumanPath ='./my_not_human_data/afhq/train/NotHuman/'
directories = {0:maskPath, 1:nonMaskPath, 2:nonHumanPath}

"""**Data Extraction:** 
*   Extracting data from above defined paths.
*   Resizing Images.
*   Reading images from disk.
*   Writing to data as np array form to trainingData.
"""

class PrepProcessingModel():
    IMAGESIZE = 100
    trainingData = []
    def makeDataSet(self):
        for label, dataDirectory in directories.items():
            print('\n\n Currently reading Label: ',label,'\n')
            for folder in tqdm(os.listdir(dataDirectory)):
                folderPath = os.path.join(dataDirectory, folder);
                for imgpath in os.listdir(folderPath):
                    imagePath = os.path.join(folderPath, imgpath);
                    img = cv2.imread(imagePath);
                    img = cv2.resize(img, (self.IMAGESIZE,self.IMAGESIZE));
                    self.trainingData.append([np.array(img), label]);
        np.random.shuffle(self.trainingData)

"""Running PreProcessing to write image marked data to trainingData."""

PrepProcessingModel = PrepProcessingModel()
PrepProcessingModel.makeDataSet()
trainingData = PrepProcessingModel.trainingData

"""**An Example of Marked images along with labels:**

*  **Masked**
"""

plt.imshow(trainingData[5][0]);
print(classes[trainingData[5][1]])

"""*  **Not Masked**"""

plt.imshow(trainingData[7008][0]);
print(classes[trainingData[7008][1]])

"""* **Not Human**"""

plt.imshow(trainingData[15056][0]);
print(classes[trainingData[15056][1]])

"""* **Creating Pytorch Dataset**"""

# Creating pytorch Dataset by converting training data set from preprocessing to tensor data type.
class BuildDataSet(Dataset):
        def __init__(self, train_data):
            self.train_data = train_data
            self.transformations = Compose([
                ToTensor(),
            ])
        
        def __getitem__(self, key):
            if isinstance(key, slice):
                raise NotImplementedError('slicing is not supported')                    
            return [
                self.transformations(self.train_data[key][0]), torch.tensor(self.train_data[key][1])
            ]
        
        def __len__(self):
            return len(self.train_data)

"""> * Creating Training Data Loader
> * Creating validation Data Loader
"""

myDataset = BuildDataSet(trainingData)
training_data, validation_data = torch.utils.data.random_split(myDataset, [(len(myDataset) - 1000), 1000])

batch_size = 32

train_dl = DataLoader(training_data, batch_size * 2, shuffle=True)
val_dl = DataLoader(validation_data, batch_size * 2)

"""# **Accuracy**"""

# Calculating accuracy from dataset
def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    true_positives_negatives = torch.sum(preds == labels).item()
    total_predictions = len(preds)
    result = true_positives_negatives/total_predictions
    accuracy = torch.tensor(result)
    return accuracy

"""# **CNN** Architecture"""

class ImageClassificationBase(nn.Module):

    def training_step(self, batch):
        images, labels = batch 
        #Calculating Loss and Generating Predictions
        return F.cross_entropy(self(images), labels.long())
    
    def validation_step(self, batch):
        images, labels = batch
        #Calculating Loss and Generating Predictions
        return {'val_loss': F.cross_entropy(self(images), labels.long()).detach(),
                 'val_acc': accuracy(self(images), labels)}
        
    def validation_epoch_end(self, outputs):

        batchLosses = []
        batchAccuracies = []

        for x in outputs:
            batchLosses.append(x['val_loss'])
            batchAccuracies.append(x['val_acc'])

        epochLosses = torch.stack(batchLosses).mean()   # Combine losses
        epochAccuracies = torch.stack(batchAccuracies).mean()      # Combine accuracies

        return {'val_loss': epochLosses.item(), 'val_acc': epochAccuracies.item()}
    
    def epoch_end(self, epoch, result):

        print("Epoch: [{}]\nTraining Data Loss: {:.4f}\nValidation Data Loss: {:.4f}\nValidation data Accuracy: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))

class CNNModel(ImageClassificationBase):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            
            #First convolution layer
            nn.Conv2d(3, 100, kernel_size=3, padding=1),
            nn.ReLU(),

            #Second convolution layer
            nn.Conv2d(100, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            
            #First pooling layer
            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8
            
            #Third convolution layer
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            
            #Fourth convolution layer
            # nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),
            # nn.ReLU(),

            #Second pooling layer
            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4
            
            #Flattening and rectification
            nn.Flatten(), 
            nn.Linear(160000, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 3))
        
    def forward(self, xb):
      return self.network(xb)

"""**Checking the availability of GPU**
> If not present then use CPU
"""

# Use GPU if available
device =  torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

def toDevice(data, device):

    """Move tensor(s) to chosen device"""
    if isinstance(data, (list, tuple)):
        myList = []
        for x in data:
            myList.append(toDevice(x, device))
        return myList
    return data.to(device, non_blocking=True)

#Overriding Dataloader methods

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield toDevice(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

train_dl = DeviceDataLoader(train_dl, device)
val_dl = DeviceDataLoader(val_dl, device)

#Training
@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = []
    for batch in val_loader:
        outputs.append(model.validation_step(batch))
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    history = []
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    for epoch in range(epochs):
        # Training Phase 
        print('epoch: ', epoch)
        model.train()
        train_losses = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result)
        history.append(result)
    return history

# Model (on GPU)
model = CNNModel()
toDevice(model, device);
model.eval();

history = [evaluate(model, val_dl)]
history

history = fit(15, 1e-3, model, train_dl, val_dl)

def plot_losses(history):
    losses = [x['val_loss'] for x in history]
    plt.plot(losses, '-x')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.title('Loss vs. No. of epochs');
    
def plot_accuracies(history):
    accuracies = [x['val_acc'] for x in history]
    plt.plot(accuracies, '-x')
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Accuracy vs. No. of epochs');

#saving to disk
torch.save(model.state_dict(), './MaskDetection.pth')

plot_losses(history)

plot_accuracies(history)

# Testing
import matplotlib.image as mpimg

def singleImage(path, label= None, show= False):
    img = cv2.imread(path)
    assert img is not None,"Image wasn't read properly"
    img = cv2.resize(img, (100, 100))
    img = torch.from_numpy(img)
    img = img.permute((2, 0,1)) # model expects image to be of shape [3, 100, 100]
    img = img.unsqueeze(dim=0).float() # convert single image to batch [1, 3, 100, 100]
    img = img.to('cuda') # Using the same device as the model
    pred = model(img)
    _, preds = torch.max(pred, dim=1)
    print(classes[preds.item()])
    
    if show:
        plt.imshow(mpimg.imread(path))
        print("the image is :" + classes[preds.item()])

def valImage(key, show = True):
    img = validation_data[key][0]
    pred = model(img.unsqueeze(dim=0).to(device))
    _, preds = torch.max(pred, dim=1)
    cv2.imshow('',img.permute(1, 2,0), cmap=cm.bgr)
    print("predicted:",classes[preds.item()])
    print("Actual:",classes[validation_data[key][1]])

singleImage('./my_human_data/Face Mask Dataset/Test/WithMask/147.png', show=True)